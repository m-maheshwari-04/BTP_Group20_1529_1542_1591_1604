{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8aa9c7",
   "metadata": {
    "id": "fb8aa9c7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import TFAutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef418b5",
   "metadata": {
    "id": "eef418b5"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3f853b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ab3f853b",
    "outputId": "943066d0-ea09-4a14-cbcf-604737ece130"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert = TFAutoModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05f87ac",
   "metadata": {
    "id": "f05f87ac"
   },
   "outputs": [],
   "source": [
    "SEQ_LEN = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001c40f1",
   "metadata": {
    "id": "001c40f1"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('processed_data.csv')\n",
    "Xids = np.zeros((len(df),SEQ_LEN))\n",
    "Xmask = np.zeros((len(df),SEQ_LEN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aQJbcqol7SIv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aQJbcqol7SIv",
    "outputId": "8a9a7a81-e567-4359-81e7-b92f86be7990"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'U': 132, 'S': 182, 'N': 568}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anot = {}\n",
    "for ele in df['Annotation']:\n",
    "  if ele in anot:\n",
    "    anot[ele]+=1\n",
    "  else:\n",
    "    anot[ele] = 1\n",
    "anot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea46f8c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bea46f8c",
    "outputId": "7c088268-2f91-4aeb-f166-bea3bbe7d08a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "882\n",
      "882\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "df = df.dropna()\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db788be9",
   "metadata": {
    "id": "db788be9"
   },
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    try:\n",
    "        tokens = tokenizer.encode_plus(df['PlainText'][i],max_length = SEQ_LEN,\n",
    "                                      truncation=True,padding='max_length',return_token_type_ids = False,return_attention_mask = True,return_tensors = 'tf')\n",
    "        Xids[i:] = tokens['input_ids']\n",
    "        Xmask[i:] = tokens['attention_mask']    \n",
    "    except:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3b0aaa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8b3b0aaa",
    "outputId": "0060e870-9cbc-4157-f61b-2bcf27c49c38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Xids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcfd944",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ddcfd944",
    "outputId": "9c14dd1c-c007-47f5-d73f-d647c5025142"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[0 1 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 2, 1, 2, 2, 0, 1, 0, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2,\n",
       "       1, 1, 1, 1, 2, 0, 2, 1, 2, 1, 1, 1, 2, 0, 1, 1, 2, 2, 2, 1, 0, 1,\n",
       "       1, 2, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 2, 1, 2, 0, 0, 1, 1,\n",
       "       1, 1, 2, 0, 1, 2, 0, 0, 1, 2, 2, 1, 1, 1, 1, 2, 0, 2, 1, 1, 1, 0,\n",
       "       1, 0, 2, 2, 1, 1, 0, 0, 1, 1, 2, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 2, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 2, 0, 0, 2, 0, 0, 0, 1, 0, 2, 2, 1,\n",
       "       2, 0, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 0, 1, 0, 2, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 2, 0, 1, 0, 0, 0, 0, 2, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 2,\n",
       "       0, 2, 2, 2, 1, 0, 1, 1, 0, 0, 2, 1, 2, 2, 0, 0, 2, 1, 1, 1, 2, 0,\n",
       "       1, 1, 2, 1, 1, 1, 0, 1, 0, 2, 1, 1, 2, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 0, 1, 2, 1, 2, 1, 0, 1, 2, 1,\n",
       "       1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 0, 0, 1, 2, 0,\n",
       "       0, 1, 1, 1, 1, 1, 2, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1,\n",
       "       0, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 0, 0, 1, 1, 2, 2, 0, 1, 1,\n",
       "       1, 1, 1, 2, 2, 0, 1, 1, 1, 2, 1, 2, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 0, 0, 2, 0, 0, 0, 0, 1, 1, 1, 2, 0,\n",
       "       0, 1, 0, 0, 2, 0, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 1, 2, 1,\n",
       "       2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2,\n",
       "       2, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2,\n",
       "       1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1,\n",
       "       1, 2, 2, 0, 2, 1, 1, 1, 0, 1, 2, 2, 1, 0, 1, 2, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 2, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1,\n",
       "       2, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1,\n",
       "       2, 1, 2, 0, 0, 1, 1, 1, 0, 2, 1, 2, 0, 0, 1, 1, 1, 1, 2, 1, 1, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = df['Annotation'].values\n",
    "print(type(arr))\n",
    "def switch(row):\n",
    "    dic = {\n",
    "        'S':0,\n",
    "        'N':1,\n",
    "        'U':2\n",
    "    }\n",
    "    return dic.get(row)\n",
    "\n",
    "arr =  np.array([switch(x) for x in arr])\n",
    "print(np.unique(arr))\n",
    "labels = np.zeros((arr.size,len(np.unique(arr))))\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1112199",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1112199",
    "outputId": "7cba8be7-425f-4bb3-bc94-0fd722e6eb5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[np.arange(arr.size),arr] = 1\n",
    "labels[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca34f81",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ca34f81",
    "outputId": "fb3edc0d-1358-4697-957e-4791ad6bafdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(200,), dtype=float64, numpy=\n",
      "array([  101.,  2156.,  3602.,  3710.,  2111., 21888.,  9068.,  6206.,\n",
      "       11560.,  2172., 19424.,  2131.,  2111., 17212.,  2278., 15181.,\n",
      "        2071., 11655., 10431.,  2135.,  4190., 25090., 28732., 15945.,\n",
      "        2270.,  2173.,  5674.,  2468.,  2406.,  6187.,  2050., 17212.,\n",
      "        2278.,  7528.,   102.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.])>, <tf.Tensor: shape=(200,), dtype=float64, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])>, <tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 0., 1.])>)\n"
     ]
    }
   ],
   "source": [
    "# tf wants data as tuple 0 index should be input, and 1 should be label\n",
    "# for bert the input tuple should have a dictionary that has mask and input_ids\n",
    "dataset = tf.data.Dataset.from_tensor_slices((Xids,Xmask,labels))\n",
    "for i in dataset.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2592046d",
   "metadata": {
    "id": "2592046d"
   },
   "outputs": [],
   "source": [
    "def map_func(input_ids,mask,labels):\n",
    "    return {'input_ids':input_ids,'attention_mask':mask},labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b030ec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "94b030ec",
    "outputId": "9bc13271-a332-4354-d6cb-2b731fd5fe2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'input_ids': <tf.Tensor: shape=(200,), dtype=float64, numpy=\n",
      "array([  101.,  2156.,  3602.,  3710.,  2111., 21888.,  9068.,  6206.,\n",
      "       11560.,  2172., 19424.,  2131.,  2111., 17212.,  2278., 15181.,\n",
      "        2071., 11655., 10431.,  2135.,  4190., 25090., 28732., 15945.,\n",
      "        2270.,  2173.,  5674.,  2468.,  2406.,  6187.,  2050., 17212.,\n",
      "        2278.,  7528.,   102.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.])>, 'attention_mask': <tf.Tensor: shape=(200,), dtype=float64, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])>}, <tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 0., 1.])>)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(map_func)\n",
    "for i in dataset.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996bee19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "996bee19",
    "outputId": "b2e72cae-91b8-4cb4-a524-9d395b370553"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.shuffle(10000).batch(8)\n",
    "DS_LEN = len(list(dataset))\n",
    "DS_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7fed2d",
   "metadata": {
    "id": "7a7fed2d"
   },
   "outputs": [],
   "source": [
    "SPLIT = .8\n",
    "train = dataset.take(round(DS_LEN*SPLIT))\n",
    "val = dataset.skip(round(DS_LEN*SPLIT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020c5843",
   "metadata": {
    "id": "020c5843"
   },
   "outputs": [],
   "source": [
    "input_ids = tf.keras.layers.Input(shape=(SEQ_LEN,),name='input_ids',dtype='int32')\n",
    "mask = tf.keras.layers.Input(shape=(SEQ_LEN,),name='attention_mask',dtype='int32')\n",
    "embeddings = bert(input_ids,attention_mask=mask)[0]\n",
    "x = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
    "# x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(256,activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(64,activation='relu')(x)\n",
    "# x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(32,activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(16,activation='relu')(x)\n",
    "# x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(8,activation='relu')(x)\n",
    "y = tf.keras.layers.Dense(3,activation='softmax',name='outputs')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1efc39",
   "metadata": {
    "id": "8f1efc39"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=[input_ids,mask],outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edecec8e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "edecec8e",
    "outputId": "e7dfc94f-ba19-4bd5-c530-d1a57ae22552"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 200)]        0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 200)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model_1 (TFBertModel)  TFBaseModelOutputWi  109482240   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 200,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " global_max_pooling1d_1 (Global  (None, 768)         0           ['tf_bert_model_1[0][0]']        \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 256)          196864      ['global_max_pooling1d_1[0][0]'] \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 128)          32896       ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 64)           8256        ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 32)           2080        ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 16)           528         ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 8)            136         ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " outputs (Dense)                (None, 3)            27          ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,723,027\n",
      "Trainable params: 109,723,027\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68beba5a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "68beba5a",
    "outputId": "0fd578f6-a8d7-41aa-abf5-46580bbce731"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 200)]        0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 200)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model_1 (TFBertModel)  TFBaseModelOutputWi  109482240   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 200,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " global_max_pooling1d_1 (Global  (None, 768)         0           ['tf_bert_model_1[0][0]']        \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 256)          196864      ['global_max_pooling1d_1[0][0]'] \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 128)          32896       ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 64)           8256        ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 32)           2080        ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 16)           528         ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 8)            136         ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " outputs (Dense)                (None, 3)            27          ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,723,027\n",
      "Trainable params: 240,787\n",
      "Non-trainable params: 109,482,240\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.layers[2].trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28501692",
   "metadata": {
    "id": "28501692"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.0001)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
    "model.compile(optimizer = optimizer,loss = loss,metrics = [acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab2450d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ab2450d",
    "outputId": "396bbdc5-46c3-4af6-80b7-6db48cf28e5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "89/89 [==============================] - 16s 183ms/step - loss: 1.1318 - accuracy: 0.7303 - val_loss: 0.5241 - val_accuracy: 0.8059\n",
      "Epoch 2/10\n",
      "89/89 [==============================] - 15s 174ms/step - loss: 1.2686 - accuracy: 0.7121 - val_loss: 0.7056 - val_accuracy: 0.7000\n",
      "Epoch 3/10\n",
      "89/89 [==============================] - 15s 171ms/step - loss: 1.1731 - accuracy: 0.7303 - val_loss: 0.6227 - val_accuracy: 0.7529\n",
      "Epoch 4/10\n",
      "89/89 [==============================] - 15s 170ms/step - loss: 1.1506 - accuracy: 0.7542 - val_loss: 0.4464 - val_accuracy: 0.8235\n",
      "Epoch 5/10\n",
      "89/89 [==============================] - 18s 196ms/step - loss: 1.3606 - accuracy: 0.7107 - val_loss: 0.4914 - val_accuracy: 0.8059\n",
      "Epoch 6/10\n",
      "89/89 [==============================] - 15s 171ms/step - loss: 1.1167 - accuracy: 0.7360 - val_loss: 0.3969 - val_accuracy: 0.8706\n",
      "Epoch 7/10\n",
      "89/89 [==============================] - 15s 171ms/step - loss: 1.1665 - accuracy: 0.7416 - val_loss: 0.4674 - val_accuracy: 0.8059\n",
      "Epoch 8/10\n",
      "89/89 [==============================] - 15s 170ms/step - loss: 1.2478 - accuracy: 0.7037 - val_loss: 0.3306 - val_accuracy: 0.9294\n",
      "Epoch 9/10\n",
      "89/89 [==============================] - 15s 170ms/step - loss: 1.2102 - accuracy: 0.7093 - val_loss: 0.4884 - val_accuracy: 0.8176\n",
      "Epoch 10/10\n",
      "89/89 [==============================] - 18s 198ms/step - loss: 1.1319 - accuracy: 0.7500 - val_loss: 0.4107 - val_accuracy: 0.8529\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train,validation_data = val,epochs = 110, class_weight={0:3.12,1:1,2:4.3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af55927",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9af55927",
    "outputId": "b74c5ea1-570d-4dba-d2f1-28f502ee9f47",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 208ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test = []\n",
    "y_pred = []\n",
    "\n",
    "for ele in val:\n",
    "\n",
    "    preds = model.predict(ele[0])\n",
    "#     print(preds)\n",
    "#     print(ele[1])\n",
    "\n",
    "    for x in preds:\n",
    "        y = np.argmax(x)\n",
    "#         print(y)\n",
    "        y_pred.append(y)\n",
    "        \n",
    "#     print('sadad')\n",
    "        \n",
    "    for x in ele[1]:\n",
    "        y = np.argmax(x)\n",
    "#         print(y)\n",
    "        y_test.append(y)\n",
    "#     print('-------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e5af9b",
   "metadata": {
    "id": "98e5af9b"
   },
   "outputs": [],
   "source": [
    "len(y_pred)\n",
    "predictions = y_pred\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,classification_report\n",
    "# from scikitplot.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7e2e9a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "id": "ea7e2e9a",
    "outputId": "a3addfb8-fb64-4b37-e626-35702165318a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score:  0.8647058823529412\n",
      "Precision_score:  0.8647058823529412\n",
      "Recall_score:  0.8647058823529412\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79        34\n",
      "           1       0.98      0.85      0.91       111\n",
      "           2       0.68      1.00      0.81        25\n",
      "\n",
      "    accuracy                           0.86       170\n",
      "   macro avg       0.80      0.89      0.83       170\n",
      "weighted avg       0.89      0.86      0.87       170\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fb6e7467b20>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot_confusion_matrix(y_test,predictions)\n",
    "cm = confusion_matrix(y_test, predictions, labels=[0,1,2])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=[0,1,2])\n",
    "acc_score = accuracy_score(y_test,predictions)\n",
    "pre_score = precision_score(y_test,predictions,average='micro')\n",
    "rec_score = recall_score(y_test,predictions,average='micro')\n",
    "print('Accuracy_score: ',acc_score)\n",
    "print('Precision_score: ',pre_score)\n",
    "print('Recall_score: ',rec_score)\n",
    "print(\"-\"*50)\n",
    "cr = classification_report(y_test,predictions)\n",
    "print(cr)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4277b4c",
   "metadata": {
    "id": "a4277b4c"
   },
   "outputs": [],
   "source": [
    "model.save(\"86accuracy_vinay.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30918ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c30918ff",
    "outputId": "c065f9e3-618f-49db-ccd5-73081665a0df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170aaabc",
   "metadata": {
    "id": "170aaabc"
   },
   "outputs": [],
   "source": [
    "model.save(\"/content/gdrive/My Drive/BTP/86accuracy_vinay.h5\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
